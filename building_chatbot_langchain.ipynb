{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variables\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000013A3BE85A80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000013A3BE86950>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Nandani, it's nice to meet you!\\n\\nAs an AI assistant, I'm always interested in learning more about people in data science. What kind of work do you do? \\n\\nAre you working on any exciting projects right now?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 22, 'total_tokens': 77, 'completion_time': 0.1, 'prompt_time': 0.002145785, 'queue_time': 0.233258044, 'total_time': 0.102145785}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0226c6f2-d15f-4b8b-a847-00cc92fc762c-0', usage_metadata={'input_tokens': 22, 'output_tokens': 55, 'total_tokens': 77})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Nandani and that you are a data scientist!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 93, 'total_tokens': 133, 'completion_time': 0.072727273, 'prompt_time': 0.00432116, 'queue_time': 0.239625037, 'total_time': 0.077048433}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e89b5626-bd64-49ee-aaf8-20751a00835b-0', usage_metadata={'input_tokens': 93, 'output_tokens': 40, 'total_tokens': 133})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\"),\n",
    "        AIMessage(content=\"Hello Nandani, it's nice to meet you!\\n\\nThat's great! Data science is a fascinating field.  What kind of work do you do as a data scientist?  \\n\\nAre you working on any exciting projects right now?\\n\"),\n",
    "        HumanMessage(content=\"Hey What is my name and what i do?\"),\n",
    "    ])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in e:\\langchain\\venv\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.34)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.18)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.6)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in e:\\langchain\\venv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in e:\\langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\langchain\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in e:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\langchain\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "##Message History\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\")],\n",
    "    config=config\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Nandani, it's nice to meet you!\\n\\nIt's great that you're a data scientist. That's a fascinating field. What kind of work do you do?\\n\\nDo you have any specific questions for me, or would you like to chat about something related to data science?\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Nandani! It's nice to meet you.  \\n\\nBeing a data scientist is so cool! What kind of projects are you working on these days?  Do you have a favorite area of data science? ðŸ˜Š \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 109, 'total_tokens': 159, 'completion_time': 0.090909091, 'prompt_time': 0.005084558, 'queue_time': 0.23575329, 'total_time': 0.095993649}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-05d7002b-89ec-4607-a940-b6344ffea215-0', usage_metadata={'input_tokens': 109, 'output_tokens': 50, 'total_tokens': 159})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\")],\n",
    "    config=config,\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Nandani! ðŸ˜Š  \\n\\nI remember that from our first introduction.  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello John!  \\n\\nIt's nice to meet you.  \\n\\nWhat can I do for you today? ðŸ˜Š \\n\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à¤¨à¤®à¤¸à¥à¤•à¤¾à¤° à¤¨à¤‚à¤¦à¤¾à¤£à¥€! à¤®à¥à¤à¥‡ à¤–à¥à¤¶à¥€ à¤¹à¥ˆ à¤•à¤¿ à¤†à¤ªà¤¨à¥‡ à¤®à¥à¤à¥‡ à¤…à¤ªà¤¨à¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤¾à¤‡à¤‚à¤Ÿà¤¿à¤¸à¥à¤Ÿ à¤ªà¤¹à¤šà¤¾à¤¨ à¤¬à¤¤à¤¾à¤¯à¤¾à¥¤ \\n\\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‹à¤ˆ à¤­à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤‚à¤•à¥‹à¤š à¤¨ à¤•à¤°à¥‡à¤‚, à¤®à¥ˆà¤‚ à¤…à¤ªà¤¨à¥€ à¤ªà¥‚à¤°à¥€ à¤•à¥à¤·à¤®à¤¤à¤¾ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤° à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤¨à¥‡ à¤•à¥€ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‚à¤à¤—à¤¾à¥¤  ðŸ˜Š\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 40, 'total_tokens': 109, 'completion_time': 0.125454545, 'prompt_time': 0.002655554, 'queue_time': 0.237241924, 'total_time': 0.128110099}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6feba658-4e68-4959-87ce-48eb5851f804-0', usage_metadata={'input_tokens': 40, 'output_tokens': 69, 'total_tokens': 109})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\")],\"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¨à¤‚à¤¦à¤¾! \\n\\nà¤®à¥à¤à¥‡ à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾ à¤²à¤— à¤°à¤¹à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤¤à¥à¤® à¤à¤• à¤¡à¥‡à¤Ÿà¤¾ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤• à¤¹à¥‹!  à¤¤à¥à¤®à¥à¤¹à¤¾à¤°à¥‡ à¤•à¥‹à¤ˆ à¤¸à¤µà¤¾à¤² à¤¹à¥ˆà¤‚ à¤œà¤¿à¤¨à¤®à¥‡à¤‚ à¤®à¥ˆà¤‚ à¤¤à¥à¤®à¥à¤¹à¤¾à¤°à¥€ à¤®à¤¦à¤¦ à¤•à¤°à¥‚à¤‚?  \\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "e:\\Langchain\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nandani\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is langchain?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Langchain is a platform for building conversational AI models', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How does it work?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='It uses a combination of machine learning and natural language processing to generate responses to user input', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, I am having fun!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi, My name is Nandani and i am a data scientist\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like to play basketball\"),\n",
    "    AIMessage(content=\"That's cool!\"),\n",
    "    HumanMessage(content=\"What is langchain?\"),\n",
    "    AIMessage(content=\"Langchain is a platform for building conversational AI models\"),\n",
    "    HumanMessage(content=\"How does it work?\"),\n",
    "    AIMessage(content=\"It uses a combination of machine learning and natural language processing to generate responses to user input\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"Yes, I am having fun!\"),\n",
    "]\n",
    "trimmer.invoke(messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import Runnable\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\"))\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    \"messages\":messages + HumanMessage()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
